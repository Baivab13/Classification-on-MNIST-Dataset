{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MNist database classification<br> <small>RÃ©da DEHAK<br> 1 July 2020</small> </center>\n",
    "\n",
    "The goal of this lab is :\n",
    "    - Evaluate your understanding of the course\n",
    "    - Try and make a comparison of different machine learning methods\n",
    "    \n",
    "This study is based on the <A href=http://yann.lecun.com/exdb/mnist/>MNist dataset</A>. It is handwritten digits dataset with a training set of 60000 samples, and a test set of 10000 samples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "- propose three different approaches to classify the MNist dataset. Compare the performance of each method and suggest solutions to improve the performance of each one. You can use all methods that you learned or not during the MSc. The goal is to obtain the best performances measure.\n",
    "- Make a video of 5 minutes maximum to justify your choices and explain your results.\n",
    "- Download the notebook and video on Teams before July 21th."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "- MNist dataset is proposed in keras.datasets toolbox, you can use this code to load the dataset or use the function mnist_load_data provided in mnist.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students.\n",
    "###### x_train and x_test parts contain greyscale RGB codes (from 0 to 255) while y_train and y_test parts contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We visualize a sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2968754da08>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOmUlEQVR4nO3df4xV9ZnH8c8jUqPyQ1wGmAhZaoPJmhoBb2CJBiVlG0ANNKYKf1SakJ3GKGkTNGv8BX/qxkLqjxBhNaWka0NsERJNlx+pQdBUr4YdUGBFnG2nEBjUBIkKiz77xxyaAed873DvuT+c5/1KJvfOee53zuN1Ppw793vO/Zq7C8Dgd1GzGwDQGIQdCIKwA0EQdiAIwg4EcXEjdzZ69GifOHFiI3cJhNLV1aXjx49bf7Wawm5mcyT9StIQSf/h7o+nHj9x4kSVy+VadgkgoVQq5daqfhlvZkMkPStprqRrJS0ys2ur/XkA6quWv9mnSTro7ofc/bSk30maX0xbAIpWS9ivkvTXPt93Z9vOYWYdZlY2s3JPT08NuwNQi1rC3t+bAN8499bd17h7yd1LbW1tNewOQC1qCXu3pAl9vh8v6XBt7QCol1rC/rakSWb2XTP7jqSFkjYX0xaAolU99ebuZ8zsPkn/pd6ptxfc/b3COgNQqJrm2d39VUmvFtQLgDridFkgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCqGkVVzTGl19+may//vrrubU333wzOXbbtm3J+qeffpqst7e3J+uHDh3KrV199dXJsUuXLk3Wb7311mT9oos4lvVVU9jNrEvSZ5K+knTG3UtFNAWgeEUc2We5+/ECfg6AOuJ1DhBErWF3SVvM7B0z6+jvAWbWYWZlMyv39PTUuDsA1ao17De6+1RJcyXda2Yzz3+Au69x95K7l9ra2mrcHYBq1RR2dz+c3R6TtFHStCKaAlC8qsNuZpeb2fCz9yX9UNLeohoDUKxa3o0fK2mjmZ39Of/p7n8spKtgTpw4kazPnz8/Wd+xY0fV+77iiiuS9VmzZiXrlc4BGDt2bG5t//79ybELFixI1iv9d19//fW5tWHDhiXHDkZVh93dD0nKfzYBtBSm3oAgCDsQBGEHgiDsQBCEHQiCS1xbwG233Zas79q1K1m/8847c2srV65Mjh0+fHiyXs8pqs8//zxZr3QJ65w5c5L19evX59YqTesNRhzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI5tkb4OTJk8n6zp07k/V77rknWX/66adza638ccqXXXZZsn7dddcl65UucS2V+LDjvlr3NwFAoQg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2Rvgww8/TNbdPVkfP358st7Kc+kpH330UbL+zDPPJOt33HFHsn7gwIHcWqXndDD6dv6WALhghB0IgrADQRB2IAjCDgRB2IEgCDsQhFWa4y1SqVTycrncsP19W1SaJ29vb0/W33///dzayJEjq+qpKKdOncqt3XTTTcmxqSWXJWn16tXJ+scff5xbGzduXHLst1WpVFK5XLb+ahWP7Gb2gpkdM7O9fbZdaWZbzeyD7HZUkQ0DKN5AXsb/WtL5S288KGm7u0+StD37HkALqxh2d98h6ZPzNs+XtC67v05SvLV0gG+Zat+gG+vuRyQpux2T90Az6zCzspmVe3p6qtwdgFrV/d14d1/j7iV3L7W1tdV7dwByVBv2o2bWLknZ7bHiWgJQD9WGfbOkxdn9xZI2FdMOgHqpeD27mb0o6RZJo82sW9JySY9L2mBmSyT9RdKP69nkYFfpuu2lS5cm67Nmzcqtvfbaa8mxI0aMSNZrtXjx4txaZ2dncuzmzZuT9aFDhybrg3UuvVoVw+7ui3JKPyi4FwB1xOmyQBCEHQiCsANBEHYgCMIOBMFHSbeAjo6OZH3v3r3J+nPPPZdbq3QZ6RtvvJGsDxs2LFl/7LHHkvWXXnopt7Z+/frk2EqX9uLCcGQHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSCYZ28BF1+c/t+watWqZP3o0aO5tY0bNybHzpgxI1lfsmRJsv7UU08l66lzCBYtyrugEvXAkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmDJ5kEgtSzyypUrk2MffvjhZN2s39V/B2z//v25tUmTJtX0s/FNNS3ZDGBwIOxAEIQdCIKwA0EQdiAIwg4EQdiBILiefRC45JJLcmvLli1Ljn355ZeT9VrPi9i6dWtujXn2xqp4ZDezF8zsmJnt7bNthZn9zcx2Z1/z6tsmgFoN5GX8ryXN6Wf7KnefnH29WmxbAIpWMezuvkPSJw3oBUAd1fIG3X1m1pm9zB+V9yAz6zCzspmVe3p6atgdgFpUG/bVkr4nabKkI5J+mfdAd1/j7iV3L7W1tVW5OwC1qirs7n7U3b9y968lrZU0rdi2ABStqrCbWd+1dH8kKb2mMICmqzjPbmYvSrpF0mgz65a0XNItZjZZkkvqkvSzOvaIGuzbty9Z7+zsrOv+77///tzaNddckxw7e/bsotsJrWLY3b2/T/J/vg69AKgjTpcFgiDsQBCEHQiCsANBEHYgCC5xHeS2bNmSrFf6qOi33norWR8xYkSyPn369Nza7bffnhy7a9euZH3q1KnJOs7FkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCefRA4fPhwbu2RRx5Jjn300UeT9RtuuKGqns565ZVXcmtz585Njr355puT9e7u7mR95MiRyXo0HNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2QeBL774Ird25syZ5Ni77rqr6HbOMWPGjNzas88+mxx79913J+sHDhxI1qdNY+2SvjiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQzLMPAnv27MmtjR8/Pjl20qRJRbczYJXm+J944olk/cknn0zWN2zYcME9DWYVj+xmNsHM/mRm+8zsPTP7ebb9SjPbamYfZLej6t8ugGoN5GX8GUnL3P2fJP2zpHvN7FpJD0ra7u6TJG3PvgfQoiqG3d2PuPu72f3PJO2TdJWk+ZLWZQ9bJ2lBvZoEULsLeoPOzCZKmiLpz5LGuvsRqfcfBEljcsZ0mFnZzMo9PT21dQugagMOu5kNk/R7Sb9w9xMDHefua9y95O6ltra2anoEUIABhd3Mhqo36L919z9km4+aWXtWb5d0rD4tAihCxak3613T93lJ+9x9ZZ/SZkmLJT2e3W6qS4eo6ODBg7m12bNnN7CTCzNkyJBkfdy4ccn6pk3pX7nUpb+XXnppcuxgNJB59hsl/UTSHjPbnW17SL0h32BmSyT9RdKP69MigCJUDLu775RkOeUfFNsOgHrhdFkgCMIOBEHYgSAIOxAEYQeC4BLXQaD3VIj+pZZMlqSdO3cm61OmTEnWT58+naynPsq6q6srOXb79u3J+vLly5P1iHPpKRzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI5tkHgdRceKWPAps5c2ayPmZMv5829ncnTqQ/tOjUqVO5NXdPjp03b16y/sADDyTrOBdHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Ignn2QWD69Om5tRUrViTHbtu2LVmvdL17LdauXZusL1y4MFnnevULw5EdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4KwStcUm9kESb+RNE7S15LWuPuvzGyFpH+VdPaC6Yfc/dXUzyqVSl4ul2tuGkD/SqWSyuVyvwsJDOSkmjOSlrn7u2Y2XNI7ZrY1q61y9yeLahRA/QxkffYjko5k9z8zs32Srqp3YwCKdUF/s5vZRElTJP0523SfmXWa2QtmNipnTIeZlc2sXOkjkgDUz4DDbmbDJP1e0i/c/YSk1ZK+J2myeo/8v+xvnLuvcfeSu5fa2toKaBlANQYUdjMbqt6g/9bd/yBJ7n7U3b9y968lrZU0rX5tAqhVxbBb7xKhz0va5+4r+2xv7/OwH0naW3x7AIoykHfjb5T0E0l7zGx3tu0hSYvMbLIkl9Ql6Wd16RBAIQbybvxOSf3N2yXn1AG0Fs6gA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFHxo6QL3ZlZj6T/7bNptKTjDWvgwrRqb63al0Rv1Sqyt390934//62hYf/Gzs3K7l5qWgMJrdpbq/Yl0Vu1GtUbL+OBIAg7EESzw76myftPadXeWrUvid6q1ZDemvo3O4DGafaRHUCDEHYgiKaE3czmmNkBMztoZg82o4c8ZtZlZnvMbLeZNXV96WwNvWNmtrfPtivNbKuZfZDd9rvGXpN6W2Fmf8ueu91mNq9JvU0wsz+Z2T4ze8/Mfp5tb+pzl+irIc9bw/9mN7Mhkv5H0r9I6pb0tqRF7v5+QxvJYWZdkkru3vQTMMxspqSTkn7j7t/Ptv27pE/c/fHsH8pR7v5vLdLbCkknm72Md7ZaUXvfZcYlLZD0UzXxuUv0daca8Lw148g+TdJBdz/k7qcl/U7S/Cb00fLcfYekT87bPF/Suuz+OvX+sjRcTm8twd2PuPu72f3PJJ1dZrypz12ir4ZoRtivkvTXPt93q7XWe3dJW8zsHTPraHYz/Rjr7kek3l8eSWOa3M/5Ki7j3UjnLTPeMs9dNcuf16oZYe9vKalWmv+70d2nSpor6d7s5SoGZkDLeDdKP8uMt4Rqlz+vVTPC3i1pQp/vx0s63IQ++uXuh7PbY5I2qvWWoj56dgXd7PZYk/v5u1Zaxru/ZcbVAs9dM5c/b0bY35Y0ycy+a2bfkbRQ0uYm9PENZnZ59saJzOxyST9U6y1FvVnS4uz+YkmbmtjLOVplGe+8ZcbV5Oeu6cufu3vDvyTNU+878h9KergZPeT0dbWk/86+3mt2b5JeVO/Luv9T7yuiJZL+QdJ2SR9kt1e2UG/rJe2R1KneYLU3qbeb1PunYaek3dnXvGY/d4m+GvK8cbosEARn0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8PPr1dLKPui0sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image_index = 50001 # Range can vary from 0 to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Method:\n",
    "\n",
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the classifier module from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As, the sklearn classifier doesnot work with more than 2-dimensional array, we reshape the array to  2-D array so it works on the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = x_train.reshape(60000, 784)\n",
    "Xtest = x_test.reshape(10000, 784)\n",
    "\n",
    "\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the values\n",
    "Xtrain =Xtrain.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "Xtrain /= 255\n",
    "Xtest /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Modellling and Fitting our Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "RFC_clf.fit(Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing and evaluating the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9698\n"
     ]
    }
   ],
   "source": [
    "predicted = RFC_clf.predict(Xtest)\n",
    "\n",
    "RFC_acc = accuracy_score(y_test,predicted)\n",
    "\n",
    "print(\"Accuracy: \", RFC_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus, the Random Forest Classifier had an accuracy of 0.9698 or 96.98%\n",
    "#### The algorithm can be further optimized by adjusting the hyperparameters such as increasing the number of predictors or by using cross-validation methods such as RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Method:\n",
    "### Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Xtrain,y_train,Xtest and y_test previously computed for Simple Neural Network. \n",
    "\n",
    "#### Importing modules and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#Importing the necessary Keras models and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model\n",
    "batch_size=128\n",
    "#output classes - 10 in this case\n",
    "num_classes=10\n",
    "epochs =12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape[0], 'train samples')\n",
    "print(Xtest.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices \n",
    "ytrain = keras.utils.to_categorical(y_train, num_classes)\n",
    "ytest = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Model\n",
    "SNN_model = Sequential()\n",
    "SNN_model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "SNN_model.add(Dropout(0.2))\n",
    "SNN_model.add(Dense(512, activation='relu'))\n",
    "SNN_model.add(Dropout(0.2))\n",
    "SNN_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dropout layer is used to counter overfitting(regularization).\n",
    "###### Dense layers define the output size. The first and second dense layer can have any value but the last dense layer should match with the output labels i.e., 10.\n",
    "###### Activation function is Rectified Linear Unit (ReLU), and Softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling and Fitting the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 - 5s - loss: 0.8426 - accuracy: 0.7369\n",
      "Epoch 2/12\n",
      "60000/60000 - 4s - loss: 0.3577 - accuracy: 0.8937\n",
      "Epoch 3/12\n",
      "60000/60000 - 4s - loss: 0.2797 - accuracy: 0.9171\n",
      "Epoch 4/12\n",
      "60000/60000 - 5s - loss: 0.2315 - accuracy: 0.9306\n",
      "Epoch 5/12\n",
      "60000/60000 - 5s - loss: 0.1921 - accuracy: 0.9417\n",
      "Epoch 6/12\n",
      "60000/60000 - 5s - loss: 0.1649 - accuracy: 0.9503\n",
      "Epoch 7/12\n",
      "60000/60000 - 5s - loss: 0.1439 - accuracy: 0.9566\n",
      "Epoch 8/12\n",
      "60000/60000 - 5s - loss: 0.1253 - accuracy: 0.9627\n",
      "Epoch 9/12\n",
      "60000/60000 - 5s - loss: 0.1137 - accuracy: 0.9657\n",
      "Epoch 10/12\n",
      "60000/60000 - 5s - loss: 0.1030 - accuracy: 0.9688\n",
      "Epoch 11/12\n",
      "60000/60000 - 5s - loss: 0.0935 - accuracy: 0.9722\n",
      "Epoch 12/12\n",
      "60000/60000 - 6s - loss: 0.0853 - accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "#Compile Model\n",
    "SNN_model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#Run Model - save metrics after each epoch in history\n",
    "history = SNN_model.fit(Xtrain, y_train,epochs=epochs,batch_size=batch_size,verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Model on Test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08903875903887674\n",
      "Test accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "#Score model against test data\n",
    "SNN_score = SNN_model.evaluate(Xtest, y_test, verbose=0)\n",
    "print('Test loss:', SNN_score[0])\n",
    "print('Test accuracy:', SNN_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus, the testing on the test set yielded an accuracy of 0.9735 or 97.35%\n",
    "#### However, there is still room for improvement by adjusting hyperparameters such as learning rate, batch_size, increasing hidden layers etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 9900\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "SNN_pred = SNN_model.predict(Xtest[image_index].reshape(1,784))\n",
    "print(SNN_pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Method:\n",
    "### Convolutional Neural Networks\n",
    "To be able to use the dataset in Keras API, we need 4-dims numpy arrays. However, as we see above, our array is 3-dims. In addition, we must normalize our data as it is always required in neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping the array to 4-dims so that it can work with the Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "input_shape = (28,28,1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train =x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the RGB codes by dividing it to the max RGB value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "x_train /= 255\n",
    "x_test /=255\n",
    "print('x_train shape:',x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary Keras models and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Sequential Model with the imported layers\n",
    "CNN_model= Sequential()\n",
    "CNN_model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "CNN_model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "CNN_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "CNN_model.add(Dropout(0.25))\n",
    "CNN_model.add(Flatten())\n",
    "CNN_model.add(Dense(128, activation='relu'))\n",
    "CNN_model.add(Dropout(0.25))\n",
    "CNN_model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I have used kernel_size of 3X3 i.e, a matrix of 3X3 dimenstions as convolution matrix.\n",
    "###### MaxPooling2D is used to extract the most prominent features from a 2D image.\n",
    "###### Flatten is used for flattening the 2D arrays for fully connected layers.\n",
    "###### Dropout layer is used to counter overfitting(regularization).\n",
    "###### Dense layers define the output size. The first dense layer can have any value but the last dense layer should match with the output labels i.e., 10.\n",
    "###### Activation function is Rectified Linear Unit (ReLU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Compiling and Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 - 185s - loss: 0.1423 - accuracy: 0.9561\n",
      "Epoch 2/12\n",
      "60000/60000 - 185s - loss: 0.0559 - accuracy: 0.9829\n",
      "Epoch 3/12\n",
      "60000/60000 - 189s - loss: 0.0395 - accuracy: 0.9876\n",
      "Epoch 4/12\n",
      "60000/60000 - 188s - loss: 0.0320 - accuracy: 0.9897\n",
      "Epoch 5/12\n",
      "60000/60000 - 183s - loss: 0.0237 - accuracy: 0.9929\n",
      "Epoch 6/12\n",
      "60000/60000 - 183s - loss: 0.0211 - accuracy: 0.9933\n",
      "Epoch 7/12\n",
      "60000/60000 - 180s - loss: 0.0166 - accuracy: 0.9945\n",
      "Epoch 8/12\n",
      "60000/60000 - 180s - loss: 0.0157 - accuracy: 0.9946\n",
      "Epoch 9/12\n",
      "60000/60000 - 184s - loss: 0.0132 - accuracy: 0.9957\n",
      "Epoch 10/12\n",
      "60000/60000 - 189s - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 11/12\n",
      "60000/60000 - 185s - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 12/12\n",
      "60000/60000 - 194s - loss: 0.0123 - accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x296872f1388>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "CNN_model.fit(x=x_train,y=y_train, epochs=epochs,verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Thus, the model had 0.9959 or 99.59% accuracy on the train set.\n",
    "###### Now, we test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 4s - loss: 0.0340 - accuracy: 0.9923\n",
      "\n",
      "Test accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the loss and accuracy of the model\n",
    "test_loss, CNN_test_acc = CNN_model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', CNN_test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Thus, the model has 0.9923 or 99.23% accuracy on the test set, which is impressive.\n",
    "#### If we want to further ameliorate the model, we can play around with hyperparameters such as learning rate, epochs, hidden layers, optmizers etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 999\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = CNN_model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "#### Comparing the three accuracy scores of Random Forest Classfier, Simple Neural Network and Convulated Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Random Forest Classifier Test accuracy: 0.9698\n",
      "\n",
      " Simple Neural Network Test accuracy: 0.9735\n",
      "\n",
      " Convulated Neural Network Test accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "print(' Random Forest Classifier Test accuracy:', RFC_acc)\n",
    "print('\\n Simple Neural Network Test accuracy:', SNN_score[1])\n",
    "print('\\n Convulated Neural Network Test accuracy:', CNN_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Perspectives:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It was observed that Convulated Neural Network had the highest accuracy with 99.23%, followed by Simple Neural Network with 97.35% accuracy and lastly by Random Forest Classifier with 96.98%.\n",
    "#### The accuracy was determined in test datasets so, even with the lowest accuracy of 96.98%, we can conclude that we have overcome overfitting for all three classifiers.\n",
    "#### As expected, neural networks proved to be better at classifying that statistical methods.\n",
    "#### It can be concluded through observation that Convolutional Neural Networks which are principally used for Image Processing is the best model for the MNIST dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
